{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Delta Estimation through an Ancilla system\n",
    "\n",
    "@anglin2000quantumjosephsonhamiltonianphase is relevant-ish to this page.\n",
    "\n",
    "We have a system described by:\n",
    "- $H_S = -J_S J_x \\otimes \\mathbb{1} + \\delta_S J_z \\otimes \\mathbb{1} + U_S J_z^2 \\otimes \\mathbb{1}$ describe's our system's @hamiltonian.\n",
    "- $H_A = -J_A \\mathbb{1} \\otimes J_x + \\delta_A \\mathbb{1} \\otimes J_z + U_A \\mathbb{1} \\otimes J_z^2$ describe's our ancilla's @hamiltonian.\n",
    "- $H_{int} = \\alpha_{xx} J_x \\otimes J_x + \\alpha_{xz} J_x \\otimes J_z + \\alpha_{zx} J_z \\otimes J_x + \\alpha_{zz} J_z \\otimes J_z$ describes the interaction terms.\n",
    "- $\\rho = (\\ket{0} \\otimes \\ket{\\alpha} ) ( \\bra{\\alpha} \\otimes \\bra{0} )$ is the initial state. We choose form to allow the ancilla state $\\ket{\\alpha}$ to be controlled, while keeping it a pure state.\n",
    "\n",
    "After letting the system evolve, we can measure the state of $H_S$ to inform ourselves about the underlying parameter $\\delta_S$ guiding the system. In particular, we can quantify our uncertainty of $\\delta_S$ through the ratio $\\frac{\\Delta A}{\\frac{\\partial}{\\partial \\delta} \\braket{A}}$, where $A:= e^{-iHt} \\rho e^{iHt}$ describes our observable. In our setup, we will consider:\n",
    "1. Evolving only the system, and measure our uncertainty of $\\delta_S$.\n",
    "2. Evolving both the system and ancilla coupled, optimizing the coupling to improve our information $\\delta_S$. As a first trial, we assume the system and ancilla have the same parameters"
   ],
   "id": "19657625ee2ca468"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T13:01:58.377161Z",
     "start_time": "2025-05-07T13:01:56.616835Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "plt.figure(figsize=(20,3))\n",
    "\n",
    "# Setup GPU use\n",
    "# https://github.com/pytorch/tutorials/issues/3263#issue-2811049983\n",
    "\n",
    "device_name = \"\"\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    device_name = torch.cuda.get_device_name(0)\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    # device_name = torch.cpu ... # TODO: Find the cpu device name\n",
    "\n",
    "torch.set_default_device(device)\n",
    "print(f\"Using {device} device: {device_name}\")"
   ],
   "id": "9caba141e131c5d3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device: NVIDIA GeForce RTX 3050 Ti Laptop GPU\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x300 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We are able to ignore the contributions of $U_S$ and $U_A$ in the 2 dimentional setup below, as in 2 dimentions $J_z^2 = \\mathbb{1}$, which has no impact on the evolution of the system",
   "id": "2501a1a6671bc2bc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T13:01:58.590744Z",
     "start_time": "2025-05-07T13:01:58.585354Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_hamiltonian(\n",
    "    j_s: torch.Tensor = torch.Tensor([0]),\n",
    "    delta_s: torch.Tensor = torch.Tensor([0]),\n",
    "    j_a: torch.Tensor = torch.Tensor([0]),\n",
    "    delta_a: torch.Tensor = torch.Tensor([0]),\n",
    "    alpha_xx: torch.Tensor = torch.Tensor([0]),\n",
    "    alpha_xz: torch.Tensor = torch.Tensor([0]),\n",
    "    alpha_zx: torch.Tensor = torch.Tensor([0]),\n",
    "    alpha_zz: torch.Tensor = torch.Tensor([0]),\n",
    ") -> torch.Tensor:\n",
    "    j_x = torch.tensor([[0,1], [1,0]], requires_grad=False)/2\n",
    "    j_z = torch.tensor([[1,0], [0,-1]], requires_grad=False)/2\n",
    "\n",
    "\n",
    "    hamiltonian_system = torch.kron(j_x, torch.eye(2, requires_grad=False))  * j_s.cuda() +\\\n",
    "                         torch.kron(j_z, torch.eye(2, requires_grad=False)) * delta_s.cuda()\n",
    "\n",
    "    hamiltonian_ancilla = torch.kron(torch.eye(2, requires_grad=False), j_x)  * j_a.cuda() +\\\n",
    "                         torch.kron(torch.eye(2, requires_grad=False), j_z) * delta_a.cuda()\n",
    "\n",
    "    hamiltonian_interactions = torch.kron(j_x, j_x) * alpha_xx.cuda() +\\\n",
    "                               torch.kron(j_x, j_z) * alpha_xz.cuda() +\\\n",
    "                               torch.kron(j_z, j_x) * alpha_zx.cuda() +\\\n",
    "                               torch.kron(j_z, j_z) * alpha_zz.cuda()\n",
    "\n",
    "\n",
    "    return hamiltonian_system + hamiltonian_ancilla + hamiltonian_interactions"
   ],
   "id": "f0f81645bfc60107",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Sanity check: Generated Hamiltonian\n",
    "\n",
    "We want to ensure that our generated hamiltonian matches the expected values"
   ],
   "id": "1a6088e4d1b409f1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T13:01:58.783011Z",
     "start_time": "2025-05-07T13:01:58.643756Z"
    }
   },
   "cell_type": "code",
   "source": "generate_hamiltonian(j_s = torch.Tensor([1])).cpu()",
   "id": "13354a857a21a162",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000, 0.5000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.5000],\n",
       "        [0.5000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.5000, 0.0000, 0.0000]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T13:01:59.093397Z",
     "start_time": "2025-05-07T13:01:59.089040Z"
    }
   },
   "cell_type": "code",
   "source": "generate_hamiltonian(delta_s = torch.Tensor([1])).cpu()",
   "id": "ec0738162d903f11",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.5000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000, -0.5000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000, -0.5000]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T13:01:59.216737Z",
     "start_time": "2025-05-07T13:01:59.210929Z"
    }
   },
   "cell_type": "code",
   "source": "generate_hamiltonian(j_a = torch.Tensor([1])).cpu()",
   "id": "fa872a3bd1dae68f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.5000, 0.0000, 0.0000],\n",
       "        [0.5000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.5000],\n",
       "        [0.0000, 0.0000, 0.5000, 0.0000]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T13:01:59.371041Z",
     "start_time": "2025-05-07T13:01:59.363603Z"
    }
   },
   "cell_type": "code",
   "source": "generate_hamiltonian(delta_a = torch.Tensor([1])).cpu()",
   "id": "54cdbd7a85e4c99f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000, -0.5000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.5000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000, -0.5000]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### As a Neural Network Layer\n",
    "\n",
    "We write the above as a Layer that represents the evolution of the system"
   ],
   "id": "8eb91e8234b7689f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T13:01:59.755629Z",
     "start_time": "2025-05-07T13:01:59.738766Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SingleSystem(torch.nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            j_s: torch.Tensor = torch.nn.Parameter(torch.Tensor([0])),\n",
    "            delta_s: torch.Tensor = torch.nn.Parameter(torch.Tensor([0])),\n",
    "            j_a: torch.Tensor = torch.nn.Parameter(torch.Tensor([0])),\n",
    "            delta_a: torch.Tensor = torch.nn.Parameter(torch.Tensor([0])),\n",
    "            alpha_xx: torch.Tensor = torch.nn.Parameter(torch.Tensor([0])),\n",
    "            alpha_xz: torch.Tensor = torch.nn.Parameter(torch.Tensor([0])),\n",
    "            alpha_zx: torch.Tensor = torch.nn.Parameter(torch.Tensor([0])),\n",
    "            alpha_zz: torch.Tensor = torch.nn.Parameter(torch.Tensor([0])),\n",
    "            time: torch.Tensor = torch.nn.Parameter(torch.Tensor([0]))\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.n_s = 2 # System size\n",
    "        self.n_a = 2 # Ancilla size\n",
    "        self.j_s = j_s\n",
    "        self.delta_s = delta_s\n",
    "        self.j_a = j_a\n",
    "        self.delta_a = delta_a\n",
    "        self.alpha_xx = alpha_xx\n",
    "        self.alpha_xz = alpha_xz\n",
    "        self.alpha_zx = alpha_zx\n",
    "        self.alpha_zz = alpha_zz\n",
    "        self.time = time\n",
    "\n",
    "    def forward(self, x): # x is our quantum state\n",
    "        with torch.device(device):\n",
    "            j_x = torch.tensor([[0,1], [1,0]], requires_grad=False)/2\n",
    "            j_z = torch.tensor([[1,0], [0,-1]], requires_grad=False)/2\n",
    "\n",
    "            hamiltonian_system = torch.kron(j_x, torch.eye(2, requires_grad=False))  * self.j_s +\\\n",
    "                                 torch.kron(j_z, torch.eye(2, requires_grad=False)) * self.delta_s\n",
    "\n",
    "            hamiltonian_ancilla = torch.kron(torch.eye(2, requires_grad=False), j_x)  * self.j_a +\\\n",
    "                                 torch.kron(torch.eye(2, requires_grad=False), j_z) * self.delta_a\n",
    "\n",
    "            hamiltonian_interactions = torch.kron(j_x, j_x) * self.alpha_xx +\\\n",
    "                                       torch.kron(j_x, j_z) * self.alpha_xz +\\\n",
    "                                       torch.kron(j_z, j_x) * self.alpha_zx +\\\n",
    "                                       torch.kron(j_z, j_z) * self.alpha_zz\n",
    "\n",
    "            hamiltonian = hamiltonian_system + hamiltonian_ancilla + hamiltonian_interactions\n",
    "\n",
    "            left_operator = torch.linalg.matrix_exp(hamiltonian * self.time * torch.tensor([-1 * 1j]))\n",
    "            right_operator = torch.linalg.matrix_exp(hamiltonian * self.time * torch.tensor([1 * 1j]))\n",
    "            final_state = torch.matmul(\n",
    "                left_operator,\n",
    "                torch.matmul(\n",
    "                    x.type(torch.complex64),\n",
    "                    right_operator\n",
    "                )\n",
    "            )\n",
    "            traced_state = torch.einsum(\n",
    "                'ijkl->ik',\n",
    "                final_state.view(self.n_s, self.n_a, self.n_s, self.n_a)\n",
    "            )\n",
    "        return traced_state\n",
    "\n",
    "    def string(self):\n",
    "        return f\"e^(iH*{self.time:.3f}), V(x) = .5 * ( {self.omega:.2f}^2 (x - {self.center:.2f})^2)\""
   ],
   "id": "72eff8bcafb082a6",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Sanity check: Tracing function\n",
    "\n",
    "We attempt a trivial partial trace to ensure our usage of `pytorch.view` and `pytorch.einsum` correctly replicates a partial trace"
   ],
   "id": "f08600870efc2e0f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T13:02:00.081126Z",
     "start_time": "2025-05-07T13:02:00.062977Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.einsum(\n",
    "    'ijkl->ik',\n",
    "    generate_hamiltonian(\n",
    "        j_s=torch.Tensor([2]),\n",
    "        delta_s=torch.Tensor([3])\n",
    "    ).view(2,2,2,2)\n",
    ").cpu()"
   ],
   "id": "2f93dba2da77673e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.,  2.],\n",
       "        [ 2., -3.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Setup optimization routine\n",
    "\n",
    "1. Setup the optimizer\n",
    "2. Build the loss function ( $\\frac{\\Delta A}{\\frac{\\partial}{\\partial \\delta} \\braket{A}}$ )\n",
    "3. Optimize away :)\n",
    "\n",
    "We numerically approximate $\\frac{\\partial}{\\partial \\delta} \\braket{A}$ as the derivative isn't analytically available with the current setup. As such we approximate it as $\\frac{\\braket{A_{\\delta_S + \\epsilon}} - \\braket{A_{\\delta_S - \\epsilon}}}{2 \\epsilon}$, giving us the rsulting formula $2 \\epsilon \\frac{\\braket{A_{\\delta_S + \\epsilon}} - \\braket{A_{\\delta_S - \\epsilon}}}{\\Delta A}$. Note that our observable is given by $\\rho_t J_z$, as we masure the angular momentum $J_z$ of the final state $\\rho_t$."
   ],
   "id": "ad2e0dde3c2401a1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T13:02:00.403950Z",
     "start_time": "2025-05-07T13:02:00.391Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SensitivityNetwork(torch.nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            j_s: torch.Tensor = torch.nn.Parameter(torch.rand([1])),\n",
    "            delta_s: torch.Tensor = torch.nn.Parameter(torch.rand([1])),\n",
    "            j_a: torch.Tensor = torch.nn.Parameter(torch.rand([1])),\n",
    "            delta_a: torch.Tensor = torch.nn.Parameter(torch.rand([1])),\n",
    "            alpha_xx: torch.Tensor = torch.nn.Parameter(torch.rand([1])),\n",
    "            alpha_xz: torch.Tensor = torch.nn.Parameter(torch.rand([1])),\n",
    "            alpha_zx: torch.Tensor = torch.nn.Parameter(torch.rand([1])),\n",
    "            alpha_zz: torch.Tensor = torch.nn.Parameter(torch.rand([1])),\n",
    "            time: torch.Tensor = torch.nn.Parameter(torch.Tensor([10]))\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.n_s = 2 # System size\n",
    "        self.n_a = 2 # Ancilla size\n",
    "        self.epsilon = 1e-4\n",
    "        self.j_s = j_s\n",
    "        self.delta_s = delta_s\n",
    "        self.j_a = j_a\n",
    "        self.delta_a = delta_a\n",
    "        self.alpha_xx = alpha_xx\n",
    "        self.alpha_xz = alpha_xz\n",
    "        self.alpha_zx = alpha_zx\n",
    "        self.alpha_zz = alpha_zz\n",
    "        self.time = time\n",
    "        self.ancilla_state: torch.Tensor = torch.nn.Parameter(torch.Tensor([[1,0],[0,0]])) # Initialize as |0> state\n",
    "\n",
    "    def forward(self): # x is our quantum state\n",
    "        initial_state = torch.kron(\n",
    "            torch.tensor([[1,0],[0,0]]),\n",
    "            self.ancilla_state\n",
    "        )\n",
    "\n",
    "        final_state_less = SingleSystem(\n",
    "            j_s=self.j_s,\n",
    "            delta_s=self.delta_s - self.epsilon,\n",
    "            j_a=self.j_a,\n",
    "            delta_a=self.delta_a,\n",
    "            alpha_xx=self.alpha_xx,\n",
    "            alpha_xz=self.alpha_xz,\n",
    "            alpha_zx=self.alpha_zx,\n",
    "            alpha_zz=self.alpha_zz,\n",
    "            time=self.time,\n",
    "        )(initial_state)\n",
    "        final_state = SingleSystem(\n",
    "            j_s=self.j_s,\n",
    "            delta_s=self.delta_s,\n",
    "            j_a=self.j_a,\n",
    "            delta_a=self.delta_a,\n",
    "            alpha_xx=self.alpha_xx,\n",
    "            alpha_xz=self.alpha_xz,\n",
    "            alpha_zx=self.alpha_zx,\n",
    "            alpha_zz=self.alpha_zz,\n",
    "            time=self.time,\n",
    "        )(initial_state)\n",
    "        final_state_more = SingleSystem(\n",
    "            j_s=self.j_s,\n",
    "            delta_s=self.delta_s + self.epsilon,\n",
    "            j_a=self.j_a,\n",
    "            delta_a=self.delta_a,\n",
    "            alpha_xx=self.alpha_xx,\n",
    "            alpha_xz=self.alpha_xz,\n",
    "            alpha_zx=self.alpha_zx,\n",
    "            alpha_zz=self.alpha_zz,\n",
    "            time=self.time,\n",
    "        )(initial_state)\n",
    "\n",
    "        j_z = (torch.tensor([[1,0], [0,-1]], requires_grad=False)/2).type(torch.complex64)\n",
    "        expectation_more = torch.trace(torch.matmul(final_state_more, j_z))\n",
    "        expectation_less = torch.trace(torch.matmul(final_state_less, j_z))\n",
    "        observable = torch.matmul(final_state, j_z)\n",
    "        variance = torch.trace(torch.matmul(observable, observable)) - torch.trace(observable)**2\n",
    "\n",
    "        # Below we have the inverse of our target, chosen to minimize our loss\n",
    "\n",
    "        return torch.tensor([\n",
    "            (expectation_more - expectation_less).real,\n",
    "            (2 * self.epsilon * variance).real,\n",
    "            variance.real,\n",
    "            observable[0][0],\n",
    "            observable[0][1],\n",
    "            observable[1][0],\n",
    "            observable[1][1],\n",
    "        ], requires_grad=True)"
   ],
   "id": "8f89ec7c7f210bc1",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "With everything prepared, we run the optimization loop",
   "id": "574e0f7f4afc09d9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T13:02:14.268416Z",
     "start_time": "2025-05-07T13:02:00.657733Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = SensitivityNetwork().cuda()\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=1e-3, #TODO: Optimize the learning rate https://discuss.pytorch.org/t/get-the-best-learning-rate-automatically/58269/4\n",
    ")\n",
    "\n",
    "for t in tqdm(range(1000)):\n",
    "\n",
    "    output = model()\n",
    "    sensitivity = torch.div(1, output[1]).real\n",
    "    optimizer.zero_grad()\n",
    "    sensitivity.backward()\n",
    "    optimizer.step()"
   ],
   "id": "63e3109a7b662303",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:09<00:00, 107.30it/s]\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T13:02:14.297124Z",
     "start_time": "2025-05-07T13:02:14.294675Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# model = SensitivityNetwork().cuda()\n",
    "#\n",
    "# optimizer = torch.optim.Adam(\n",
    "#     model.parameters(),\n",
    "#     lr=1e-3, #TODO: Optimize the learning rate https://discuss.pytorch.org/t/get-the-best-learning-rate-automatically/58269/4\n",
    "# )\n",
    "\n",
    "# output = model()\n",
    "# sensitivity = torch.div(1, output[1]).real\n",
    "#\n",
    "# sensitivity"
   ],
   "id": "fcf9cf809db82a72",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T13:02:14.353719Z",
     "start_time": "2025-05-07T13:02:14.346074Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name}: {param.data}\")"
   ],
   "id": "38281a7d61ddc82e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "j_s: tensor([0.9689], device='cuda:0')\n",
      "delta_s: tensor([0.4526], device='cuda:0')\n",
      "j_a: tensor([0.4923], device='cuda:0')\n",
      "delta_a: tensor([0.6583], device='cuda:0')\n",
      "alpha_xx: tensor([0.9528], device='cuda:0')\n",
      "alpha_xz: tensor([0.3967], device='cuda:0')\n",
      "alpha_zx: tensor([0.6671], device='cuda:0')\n",
      "alpha_zz: tensor([0.1065], device='cuda:0')\n",
      "time: tensor([10.], device='cuda:0')\n",
      "ancilla_state: tensor([[1., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T13:02:14.407226Z",
     "start_time": "2025-05-07T13:02:14.403643Z"
    }
   },
   "cell_type": "code",
   "source": "sensitivity",
   "id": "b3875409534a613b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-6.7109e+11, device='cuda:0', grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T13:02:14.460398Z",
     "start_time": "2025-05-07T13:02:14.456523Z"
    }
   },
   "cell_type": "code",
   "source": "output",
   "id": "9c5816951ed2e598",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 8.0615e-05+0.0000e+00j, -1.4901e-12+0.0000e+00j,\n",
       "        -7.4506e-09+0.0000e+00j,  1.9031e-01-1.1548e-07j,\n",
       "        -3.0608e-01-5.0155e-02j,  3.0608e-01-5.0155e-02j,\n",
       "        -5.0550e-01+3.7253e-08j], device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T13:02:14.512737Z",
     "start_time": "2025-05-07T13:02:14.508840Z"
    }
   },
   "cell_type": "code",
   "source": [
    "obs = torch.tensor([[3.6754e-01-2.9802e-08j, -2.6959e-01-1.2645e-01j], [2.6959e-01-1.2645e-01j, -2.4125e-01-3.9116e-08j]])\n",
    "obs.cpu()"
   ],
   "id": "4598f19229c8e7af",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3675-2.9802e-08j, -0.2696-1.2645e-01j],\n",
       "        [ 0.2696-1.2645e-01j, -0.2412-3.9116e-08j]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T13:02:14.615271Z",
     "start_time": "2025-05-07T13:02:14.611380Z"
    }
   },
   "cell_type": "code",
   "source": "torch.matmul(obs, obs).cpu()",
   "id": "6b034b9179881f9c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0464-2.2161e-08j, -0.0340-1.5969e-02j],\n",
       "        [ 0.0340-1.5969e-02j, -0.0305+1.9064e-08j]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T13:02:14.742116Z",
     "start_time": "2025-05-07T13:02:14.735357Z"
    }
   },
   "cell_type": "code",
   "source": "torch.trace(torch.matmul(obs, obs))",
   "id": "5146fab7c59f197b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0160-3.0973e-09j, device='cuda:0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T13:02:14.954015Z",
     "start_time": "2025-05-07T13:02:14.947209Z"
    }
   },
   "cell_type": "code",
   "source": "torch.trace(obs)**2",
   "id": "a177680a4de9dd90",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0159-1.7407e-08j, device='cuda:0')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T13:02:15.075043Z",
     "start_time": "2025-05-07T13:02:15.068038Z"
    }
   },
   "cell_type": "code",
   "source": "torch.trace(torch.matmul(obs, obs)) - torch.trace(obs)**2",
   "id": "6076160e282f0dba",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.3132e-06+1.4310e-08j, device='cuda:0')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T13:02:15.131902Z",
     "start_time": "2025-05-07T13:02:15.129295Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "e9c33f34b67b7f93",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
