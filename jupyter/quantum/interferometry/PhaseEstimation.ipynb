{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Steps\n",
    "\n",
    "1. Build a `RunOptions` generator with the parameters of interest, namely $dim_S, J_S, \\delta_S, U_S, dim_A, J_A, \\delta_A, U_A, \\alpha_{xx}, \\alpha_{xz}, \\alpha_{zx}, \\alpha_{zz}, t$. We need a decent range for $\\delta_S$ for the Bayesian update side of things. We assume a uniform prior on the cartesian product.\n",
    "2. Calculate the probabilities for the $J_z$ measurement for each value. This is a `dict`, as $J_z$ can have multiple outcomes.\n",
    "3. Use the probabilities to build the expected likelihood function over all inputs, for a given range of $N_{trials}$. This also requires a \"True\" set of values for each parameter.\n",
    "4. Use the likelihood to build the marginal distribution for all variables.\n",
    "5. Save the std variation for each estimated variable!\n",
    "6. Plot $\\Delta$ against the $N_{trials}$, keeping the parameters of the plot saved"
   ],
   "id": "73ea84504c9e99d5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-27T16:11:02.788693Z",
     "start_time": "2024-12-27T16:11:02.243960Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dataclasses import dataclass, field\n",
    "from src.angular_momentum import generate_spin_matrices\n",
    "from tqdm import tqdm\n",
    "import functools\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "figure(figsize=(16, 6))\n",
    "\n",
    "# Create new `pandas` methods which use `tqdm` progress\n",
    "# (can use tqdm_gui, optional kwargs, etc.)\n",
    "tqdm.pandas()"
   ],
   "id": "29633e094bb408c0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "@dataclass\n",
    "class Settings:\n",
    "    dim_s: int\n",
    "    dim_a: int\n",
    "    probability_error_tolerance: float\n",
    "    system_jx: np.array = field(init=False)\n",
    "    system_jz: np.array = field(init=False)\n",
    "    ancilla_jx: np.array = field(init=False)\n",
    "    ancilla_jz: np.array = field(init=False)\n",
    "    initial_state: np.array = field(init=False)\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.system_jx, self.system_jz = generate_spin_matrices(dim=self.dim_s)\n",
    "        self.ancilla_jx, self.ancilla_jz = generate_spin_matrices(dim=self.dim_a)\n",
    "        self.initial_state = np.zeros(self.dim_s * self.dim_a)\n",
    "        self.initial_state[0] = 1\n",
    "        self.initial_state = np.outer(self.initial_state, self.initial_state)\n",
    "\n",
    "    def generate_hamiltonian(\n",
    "        self,\n",
    "        j_s: float,\n",
    "        u_s: float,\n",
    "        delta_s: float,\n",
    "        j_a: float,\n",
    "        u_a: float,\n",
    "        delta_a: float,\n",
    "        alpha_xx: float,\n",
    "        alpha_xz: float,\n",
    "        alpha_zx: float,\n",
    "        alpha_zz: float,\n",
    "    ) -> np.array:\n",
    "        system_hamiltonian = np.kron(\n",
    "            -1 * j_s * self.system_jx + u_s * self.system_jz @ self.system_jz + delta_s * self.system_jz,\n",
    "            np.divide(np.eye(self.dim_a), self.dim_a)\n",
    "        )\n",
    "        ancillary_hamiltonian = np.kron(\n",
    "            np.divide(np.eye(self.dim_s), self.dim_s),\n",
    "            -1 * j_a * self.ancilla_jx + u_a * self.ancilla_jz @ self.ancilla_jz + delta_a * self.ancilla_jz\n",
    "        )\n",
    "        interaction_hamiltonian = functools.reduce(\n",
    "            lambda x, y: x + y,\n",
    "            [\n",
    "                alpha_xx * np.kron(self.system_jx, self.ancilla_jx),\n",
    "                alpha_xz * np.kron(self.system_jx, self.ancilla_jz),\n",
    "                alpha_zx * np.kron(self.system_jz, self.ancilla_jx),\n",
    "                alpha_zz * np.kron(self.system_jz, self.ancilla_jz),\n",
    "            ]\n",
    "        )\n",
    "        return system_hamiltonian + ancillary_hamiltonian + interaction_hamiltonian\n",
    "\n",
    "    def trace_out_ancillary(self, state: np.array):\n",
    "        return np.trace(\n",
    "            np.array(state).reshape(self.dim_s, self.dim_a, self.dim_s, self.dim_a),\n",
    "            axis1=1,\n",
    "            axis2=3\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def calculate_final_state(\n",
    "        hamiltonian: np.array,\n",
    "        initial_state: np.ndarray,\n",
    "        t: float = 0,\n",
    "    ) -> np.array:\n",
    "        return scipy.linalg.expm(-1j * t * hamiltonian) @ initial_state @ scipy.linalg.expm(1j * t * hamiltonian)\n",
    "\n",
    "    def calculate_probabilities(self, final_state: np.array) -> np.array:\n",
    "        system_state = self.trace_out_ancillary(state=final_state)\n",
    "        probabilities = [np.abs(x)**2 for x in np.diag(system_state)] # TODO: Ensure these actually up to 1!!!\n",
    "        # assert np.abs(np.sum(probabilities) - 1) < settings.probability_error_tolerance, f\"âš  The observed probabilities {probabilities} are unphysical by {np.abs(np.sum(probabilities) - 1):.5f}%\"\n",
    "        return probabilities"
   ],
   "id": "5c1406b4c0cfed7f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Initial state $\\ket{0} \\otimes \\ket{0}$",
   "id": "35713f1e1bb923bb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "settings = Settings(\n",
    "    dim_s= 2,\n",
    "    dim_a= 1,\n",
    "    probability_error_tolerance= .001,\n",
    ")\n",
    "pd.DataFrame(settings.initial_state).style.background_gradient(cmap='viridis')"
   ],
   "id": "792ff450b6e7ab53",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Build Generator Object",
   "id": "e19345f53150897a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df = pd.DataFrame([\n",
    "    {\n",
    "        \"j_s\": j_s,\n",
    "        \"u_s\": u_s,\n",
    "        \"delta_s\": delta_s,\n",
    "        \"j_a\": j_a,\n",
    "        \"u_a\": u_a,\n",
    "        \"delta_a\": delta_a,\n",
    "        \"alpha_xx\": alpha_xx,\n",
    "        \"alpha_xz\": alpha_xz,\n",
    "        \"alpha_zx\": alpha_zx,\n",
    "        \"alpha_zz\": alpha_zz,\n",
    "        \"time\": time\n",
    "    }\n",
    "    for j_s, u_s, delta_s, j_a, u_a, delta_a, alpha_xx, alpha_xz, alpha_zx, alpha_zz, time\n",
    "    in itertools.product(\n",
    "        np.linspace(.1999, .2001, 11), # j_s: float,\n",
    "        np.linspace(.0999, .1001, 11), # u_s: float,\n",
    "        np.linspace(1.1, 1.3, 1001), # delta_s: float,\n",
    "        [.3], # j_a: float,\n",
    "        [.1], # u_a: float,\n",
    "        [1], # delta_a: float,\n",
    "        [0], # alpha_xx: float,\n",
    "        [0], # alpha_xz: float,\n",
    "        [0], # alpha_zx: float,\n",
    "        [0], # alpha_zz: float,\n",
    "        np.linspace(4.99, 5.01, 3), # time: float\n",
    "    )],\n",
    ")\n",
    "df.sample(10).style.background_gradient(cmap='viridis', axis=0)"
   ],
   "id": "37e275c005678f1b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Define True System",
   "id": "90962d73b329521e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "true_values = {\n",
    "    \"j_s\": .2,\n",
    "    \"u_s\": .1,\n",
    "    \"delta_s\": 1.2,\n",
    "    \"j_a\": .3,\n",
    "    \"u_a\": .1,\n",
    "    \"delta_a\": 1,\n",
    "    \"alpha_xx\": 0,\n",
    "    \"alpha_xz\": 0,\n",
    "    \"alpha_zx\": 0,\n",
    "    \"alpha_zz\": 0,\n",
    "    \"time\": 5,\n",
    "}"
   ],
   "id": "26a741b79af1f933",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Calculate measurement probabilities",
   "id": "7b71cb6559fb71c0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def calculate_measurement_probabilities(row: pd.Series) -> np.array:\n",
    "    hamiltonian = settings.generate_hamiltonian(\n",
    "        j_s = row[\"j_s\"],\n",
    "        u_s = row[\"u_s\"],\n",
    "        delta_s = row[\"delta_s\"],\n",
    "        j_a = row[\"j_a\"],\n",
    "        u_a = row[\"u_a\"],\n",
    "        delta_a = row[\"delta_a\"],\n",
    "        alpha_xx = row[\"alpha_xx\"],\n",
    "        alpha_xz = row[\"alpha_xz\"],\n",
    "        alpha_zx = row[\"alpha_zx\"],\n",
    "        alpha_zz = row[\"alpha_zz\"]\n",
    "    )\n",
    "    final_state = settings.calculate_final_state(\n",
    "        hamiltonian = hamiltonian,\n",
    "        initial_state = settings.initial_state,\n",
    "        t = row[\"time\"],\n",
    "    )\n",
    "    # return final_state\n",
    "    measurement_probabilities = settings.calculate_probabilities(final_state)\n",
    "    return measurement_probabilities\n",
    "    # return np.divide(final_probabilities, np.sum(final_probabilities))\n",
    "\n",
    "df[\"probabilities\"] = df.progress_apply(calculate_measurement_probabilities, axis=1) # i.e. Prob[J_z=k] for k in range(0, dim_s)\n",
    "df[\"final_state_error\"] = df.progress_apply(lambda row: np.abs(np.sum(row[\"probabilities\"]) - 1), axis=1)\n",
    "\n",
    "df.sample(30).style.background_gradient(cmap='viridis', axis=0)"
   ],
   "id": "69a07087e673b63c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Calculate likelihoods",
   "id": "2bd38f7edef0acc3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "true_likelihoods = calculate_measurement_probabilities(true_values)\n",
    "# true_likelihoods /= np.prod(true_likelihoods)\n",
    "true_likelihoods"
   ],
   "id": "d2019709f1224f9a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Define n_trials",
   "id": "b277ee4385731ec0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df = df.merge(\n",
    "    pd.DataFrame([{\"n_trials\": 2**x} for x in range(16)]),\n",
    "    how='cross'\n",
    ")\n",
    "df.astype({'n_trials': 'int32'}, copy=False)\n",
    "df.shape"
   ],
   "id": "a4d06a78893fbf28",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "vector = np.array([.1, .9])\n",
    "n = 1000\n",
    "scipy.special.loggamma(n * np.sum(vector)) - np.sum(scipy.special.loggamma(n * vector))\n",
    "np.sum((n * vector - 1)*np.log(vector))"
   ],
   "id": "7abeeabfe7265ac5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def calculate_log_likelihood(true_probabilities: np.array, expected_probabilities: np.array, n_trials: float) -> float:\n",
    "    true_probabilities = np.array(true_probabilities)\n",
    "    expected_probabilities = np.array(expected_probabilities)\n",
    "    # return np.sum([\n",
    "    #     scipy.special.loggamma(n_trials * np.sum(expected_probabilities)),\n",
    "    #     np.sum((n_trials * expected_probabilities - 1)*np.log(true_probabilities)),\n",
    "    #     np.sum(scipy.special.loggamma(n_trials * expected_probabilities)),\n",
    "    # ])\n",
    "    return n_trials * np.sum(expected_probabilities*np.log(true_probabilities))\n",
    "\n",
    "df[\"log_likelihood\"] = df.progress_apply(lambda row: calculate_log_likelihood(\n",
    "    true_probabilities=true_likelihoods,\n",
    "    expected_probabilities=row[\"probabilities\"],\n",
    "    n_trials=row[\"n_trials\"]\n",
    "), axis=1)"
   ],
   "id": "e74710cabfdf0b0f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# df.sample(30).style.background_gradient(cmap='viridis', axis=0)\n",
    "df.sort_values(\"log_likelihood\", ascending=False).head(10).style.background_gradient(cmap='viridis', axis=0)"
   ],
   "id": "56a8095927253b0a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Take likelihood marginals",
   "id": "e512db3e2fd8e08a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "aggregates = pd.DataFrame()\n",
    "for parameter in [par for par in true_values.keys() if len(set(df[par]))>=5]: # Only plot parameters for which we attempted at least 5 different values\n",
    "    temp_df = df[[parameter, \"n_trials\", \"log_likelihood\"]]\n",
    "    temp_df.sample(10)\n",
    "\n",
    "    likelihood_df = temp_df\\\n",
    "    .groupby([parameter, \"n_trials\"])[\"log_likelihood\"]\\\n",
    "    .agg(lambda row: np.sum(np.exp(row)))\\\n",
    "    .reset_index()\\\n",
    "    .pivot(columns=\"n_trials\", index=parameter, values=\"log_likelihood\")\n",
    "\n",
    "    likelihood_df /= likelihood_df.sum(axis=0)\n",
    "    # mean = np.divide(df[\"delta_s\"] @ df[\"likelihood\"], df[\"likelihood\"].sum())\n",
    "    likelihood_df.plot.line(figsize=(16,3), title=parameter)\n",
    "\n",
    "    aggregates = pd.concat([aggregates, pd.DataFrame({\n",
    "        \"variable\": parameter,\n",
    "        \"n_trials\": likelihood_df.columns,\n",
    "        \"mean\": likelihood_df.apply(lambda row: np.average(likelihood_df.index, weights=row), axis=0),\n",
    "        \"var\": likelihood_df.apply(lambda row: np.average(row**2, weights=likelihood_df.index) - np.average(row, weights=likelihood_df.index)**2, axis=0)\n",
    "    })])\n"
   ],
   "id": "b691641348d53440",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "aggregates.pivot(index=\"n_trials\", columns=\"variable\", values=\"var\")",
   "id": "6610ed90df77652",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "aggregates.pivot(index=\"n_trials\", columns=\"variable\", values=\"var\").plot.line(figsize=(16,3),logx=True)",
   "id": "b53db430e2674778",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "4162782923e3c436",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
